{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filename parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "piece of code that delves into the intricacies of space weather monitoring using data from the China Seismo-Electromagnetic Satellite (CSES). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The project directory, named CSES_files, serves as the repository for our data files. These files, stored in `HDF5` format, contain valuable measurements from various instruments aboard the CSES satellite. The initial step involves importing the necessary libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import xarray as xr\n",
    "import xarray\n",
    "from shapely import geometry\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each library plays a crucial role in data manipulation, visualization, and geographic data handling. For instance, `xarray` is used for handling **multi-dimensional arrays** efficiently, while `geopandas` provides tools for **geographic data manipulation**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Paths and Dataset Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define project directory and the names for different datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code begins by defining the project directory and listing the `HDF5` files to be processed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percorso cartella di progetto: /home/wvuser/CSESfiles\n"
     ]
    }
   ],
   "source": [
    "project_dir = \"/home/wvuser/CSESfiles\"\n",
    "\n",
    "print(f\"Percorso cartella di progetto: {project_dir}\")\n",
    "\n",
    "EFD1 = 'CSES_01_EFD_1_L02_A1_213330_20211206_164953_20211206_172707_000.h5'\n",
    "HEP1 = 'CSES_01_HEP_1_L02_A4_176401_20210407_182209_20210407_190029_000.h5'\n",
    "HEP4 = 'CSES_01_HEP_4_L02_A4_202091_20210923_184621_20210923_192441_000.h5'\n",
    "LAP1 = 'CSES_01_LAP_1_L02_A3_174201_20210324_070216_20210324_073942_000.h5'\n",
    "SCM1 = 'CSES_01_SCM_1_L02_A2_183380_20210523_154551_20210523_162126_000.h5'\n",
    "HEPD = 'CSES_HEP_DDD_0219741_20220117_214156_20220117_230638_L3_0000267631.h5'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dataset` function is then defined to open an `xarray` dataset from a given file path:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to open an xarray dataset from a given path\n",
    "def dataset(path):\n",
    "    return xarray.open_dataset(path, engine = 'h5netcdf', phony_dims = 'sort')\n",
    "\n",
    "# Function to list all variable names in a dataset\n",
    "def variables(data):\n",
    "    return list(data.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List of file paths to be processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/wvuser/CSESfiles/CSES_01_EFD_1_L02_A1_213330_20211206_164953_20211206_172707_000.h5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "file_list = [\n",
    "    os.path.join(project_dir, EFD1),\n",
    "    os.path.join(project_dir, HEP1),\n",
    "    os.path.join(project_dir, HEP4),\n",
    "    os.path.join(project_dir, LAP1),\n",
    "    os.path.join(project_dir, SCM1),\n",
    "    os.path.join(project_dir, HEPD)\n",
    "]\n",
    "\n",
    "print(file_list[0])\n",
    "\n",
    "# Redefine the dataset function to open xarray datasets\n",
    "def dataset(path):\n",
    "    return xarray.open_dataset(path, engine = 'h5netcdf', phony_dims = 'sort')\n",
    "\n",
    "# Redefine the variables function to list all variable names in a dataset\n",
    "def variables(data):\n",
    "    return list(data.keys())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the data better, the code extracts `metadata` such as `start` and `end dates`, and `orbit numbers` from the filenames. This is achieved using the `extract_dates` and `extract_orbit` functions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract satellite number from a file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_name(file_path):\n",
    "    return os.path.basename(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_satellite_number(file_name):\n",
    "    try:\n",
    "        parts = file_name.split('_')\n",
    "        satellite_number = parts[1]\n",
    "        return satellite_number\n",
    "    except IndexError:\n",
    "        print(f\"Errore nell'estrazione del numero del satellite per il file {file_name}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract instrument code from a file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_instrument_code(file_name):\n",
    "    try:\n",
    "        parts = file_name.split('_')\n",
    "        instrument_code = parts[2]\n",
    "        return instrument_code\n",
    "    except IndexError:\n",
    "        print(f\"Errore nell'estrazione del codice strumento per il file {file_name}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract instrument number from a file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_instrument_number(file_name):\n",
    "    try:\n",
    "        parts = file_name.split('_')\n",
    "        instrument_number = parts[3]\n",
    "        return instrument_number\n",
    "    except IndexError:\n",
    "        print(f\"Errore nell'estrazione del numero strumento per il file {file_name}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract data level from a file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_level(file_name):\n",
    "    try:\n",
    "        parts = file_name.split('_')\n",
    "        data_level = parts[4]\n",
    "        return data_level\n",
    "    except IndexError:\n",
    "        print(f\"Errore nell'estrazione del livello dei dati per il file {file_name}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract orbit number from a file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_orbit(file_name):\n",
    "    try:\n",
    "        base_name = os.path.basename(file_name)\n",
    "        parts = base_name.split('_')\n",
    "        start_index = None\n",
    "        for i in range(len(parts)):\n",
    "            if parts[i].isdigit() and len(parts[i]) == 8: \n",
    "                start_index = i\n",
    "                break\n",
    "    \n",
    "        if start_index is None:\n",
    "            raise ValueError(f\"Formato data non trovato nel nome del file: {file_name}\")\n",
    "        \n",
    "        orbit = parts[start_index - 1]  \n",
    "        return orbit\n",
    "    except ValueError as e:\n",
    "        print(f\"Errore nel parsing dell'orbita per il file {file_name}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract start and end dates from a file name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_dates(file_name):\n",
    "    try:\n",
    "        base_name = os.path.basename(file_name) #returns the final component of a pathname\n",
    "        parts = base_name.split('_')\n",
    "        \n",
    "        #find the index of the part that contains the start_date\n",
    "        start_index = None\n",
    "        for i in range(len(parts)):\n",
    "            if parts[i].isdigit() and len(parts[i]) == 8:  # find the part with data format YYYYMMDD\n",
    "                start_index = i\n",
    "                break\n",
    "        \n",
    "        if start_index is None:\n",
    "            raise ValueError(f\"Formato data non trovato nel nome del file: {file_name}\")\n",
    "        \n",
    "        start_date_str = '_'.join(parts[start_index:start_index + 2]) \n",
    "        end_date_str = '_'.join(parts[start_index + 2:start_index + 4])  \n",
    "        \n",
    "        start_date = datetime.strptime(start_date_str, '%Y%m%d_%H%M%S')\n",
    "        end_date = datetime.strptime(end_date_str, '%Y%m%d_%H%M%S')\n",
    "        \n",
    "        return start_date, end_date\n",
    "    except ValueError as e:\n",
    "        print(f\"Errore nel parsing delle date per il file {file_name}: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parse_filename function to include the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_filename(file_name):\n",
    "    file = get_file_name(file_name)\n",
    "    satellite_nr = extract_satellite_number(file_name)\n",
    "    instrument_code = extract_instrument_code(file_name)\n",
    "    instrument_nr = extract_instrument_number(file_name)\n",
    "    data_l = extract_data_level(file_name)\n",
    "    start_date, end_date = extract_dates(file_name)\n",
    "    semiorbit_nr = extract_orbit(file_name)\n",
    "    return {\n",
    "        'file_name': file,\n",
    "        \"satellite_nr\": satellite_nr,\n",
    "        \"instrument_code\": instrument_code,\n",
    "        \"instrument_nr\": instrument_nr,\n",
    "        \"data_l\":data_l,\n",
    "        \"semiorbit_nr\": semiorbit_nr,\n",
    "        \"start_date\": start_date, \n",
    "        \"end_date\" : end_date\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parsed metadata is stored in a list of dictionaries, which is then converted into a pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>satellite_nr</th>\n",
       "      <th>instrument_code</th>\n",
       "      <th>instrument_nr</th>\n",
       "      <th>data_l</th>\n",
       "      <th>semiorbit_nr</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CSES_01_EFD_1_L02_A1_213330_20211206_164953_20...</td>\n",
       "      <td>01</td>\n",
       "      <td>EFD</td>\n",
       "      <td>1</td>\n",
       "      <td>L02</td>\n",
       "      <td>213330</td>\n",
       "      <td>2021-12-06 16:49:53</td>\n",
       "      <td>2021-12-06 17:27:07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CSES_01_HEP_1_L02_A4_176401_20210407_182209_20...</td>\n",
       "      <td>01</td>\n",
       "      <td>HEP</td>\n",
       "      <td>1</td>\n",
       "      <td>L02</td>\n",
       "      <td>176401</td>\n",
       "      <td>2021-04-07 18:22:09</td>\n",
       "      <td>2021-04-07 19:00:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CSES_01_HEP_4_L02_A4_202091_20210923_184621_20...</td>\n",
       "      <td>01</td>\n",
       "      <td>HEP</td>\n",
       "      <td>4</td>\n",
       "      <td>L02</td>\n",
       "      <td>202091</td>\n",
       "      <td>2021-09-23 18:46:21</td>\n",
       "      <td>2021-09-23 19:24:41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CSES_01_LAP_1_L02_A3_174201_20210324_070216_20...</td>\n",
       "      <td>01</td>\n",
       "      <td>LAP</td>\n",
       "      <td>1</td>\n",
       "      <td>L02</td>\n",
       "      <td>174201</td>\n",
       "      <td>2021-03-24 07:02:16</td>\n",
       "      <td>2021-03-24 07:39:42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CSES_01_SCM_1_L02_A2_183380_20210523_154551_20...</td>\n",
       "      <td>01</td>\n",
       "      <td>SCM</td>\n",
       "      <td>1</td>\n",
       "      <td>L02</td>\n",
       "      <td>183380</td>\n",
       "      <td>2021-05-23 15:45:51</td>\n",
       "      <td>2021-05-23 16:21:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>CSES_HEP_DDD_0219741_20220117_214156_20220117_...</td>\n",
       "      <td>HEP</td>\n",
       "      <td>DDD</td>\n",
       "      <td>0219741</td>\n",
       "      <td>20220117</td>\n",
       "      <td>0219741</td>\n",
       "      <td>2022-01-17 21:41:56</td>\n",
       "      <td>2022-01-17 23:06:38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           file_name satellite_nr  \\\n",
       "0  CSES_01_EFD_1_L02_A1_213330_20211206_164953_20...           01   \n",
       "1  CSES_01_HEP_1_L02_A4_176401_20210407_182209_20...           01   \n",
       "2  CSES_01_HEP_4_L02_A4_202091_20210923_184621_20...           01   \n",
       "3  CSES_01_LAP_1_L02_A3_174201_20210324_070216_20...           01   \n",
       "4  CSES_01_SCM_1_L02_A2_183380_20210523_154551_20...           01   \n",
       "5  CSES_HEP_DDD_0219741_20220117_214156_20220117_...          HEP   \n",
       "\n",
       "  instrument_code instrument_nr    data_l semiorbit_nr          start_date  \\\n",
       "0             EFD             1       L02       213330 2021-12-06 16:49:53   \n",
       "1             HEP             1       L02       176401 2021-04-07 18:22:09   \n",
       "2             HEP             4       L02       202091 2021-09-23 18:46:21   \n",
       "3             LAP             1       L02       174201 2021-03-24 07:02:16   \n",
       "4             SCM             1       L02       183380 2021-05-23 15:45:51   \n",
       "5             DDD       0219741  20220117      0219741 2022-01-17 21:41:56   \n",
       "\n",
       "             end_date  \n",
       "0 2021-12-06 17:27:07  \n",
       "1 2021-04-07 19:00:29  \n",
       "2 2021-09-23 19:24:41  \n",
       "3 2021-03-24 07:39:42  \n",
       "4 2021-05-23 16:21:26  \n",
       "5 2022-01-17 23:06:38  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = []\n",
    "\n",
    "for file in file_list:\n",
    "    metadata = parse_filename(file)\n",
    "    if metadata:\n",
    "        data.append(metadata)\n",
    "    #metadata[\"semiorbit_nr\"]\n",
    "    #semiorbits_geo[metadata[\"semiorbit_nr\"]]\n",
    "    # {\n",
    "    #     \"start_date\": ...\n",
    "    #     \"start_date\": ...\n",
    "    #     \"start_date\": ...\n",
    "    # }\n",
    "if data:\n",
    "    columns = list(data[0].keys())\n",
    "else:\n",
    "    columns = []\n",
    "\n",
    "\n",
    "df = pd.DataFrame(data, columns=columns)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geographic Data Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `polygon` function allows us to create a polygon from geographic coordinates and filter out data points that fall outside this polygon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polygon(points, data):\n",
    "    \n",
    "    ds = dataset(data)\n",
    "\n",
    "    geo_lat = ds.GEO_LAT\n",
    "    geo_lon = ds.GEO_LON\n",
    "\n",
    "\n",
    "    latitudes = [point[1] for point in points]\n",
    "    longitudes = [point[0] for point in points]\n",
    "\n",
    "    lat_min = min(latitudes)\n",
    "    lat_max = max(latitudes)\n",
    "    lon_min = min(longitudes)\n",
    "    lon_max = max(longitudes)\n",
    "\n",
    "    lat_mask = (geo_lat >= lat_min) & (geo_lat <= lat_max)\n",
    "    lon_mask = (geo_lon >= lon_min) & (geo_lon <= lon_max)\n",
    "\n",
    "    print(f\"Bounding Box - lat_min: {lat_min}, lat_max: {lat_max}, lon_min: {lon_min}, lon_max: {lon_max}\")\n",
    "\n",
    "    final_mask = lat_mask + lon_mask\n",
    "\n",
    "    filtered_subset = ds.where(final_mask, drop=True)\n",
    "\n",
    "    if filtered_subset.GEO_LAT.size > 0 and filtered_subset.GEO_LON.size > 0:\n",
    "        return(filtered_subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n",
      "Bounding Box - lat_min: 30.0, lat_max: 50.0, lon_min: 100.0, lon_max: 120.0\n",
      "[[-33.497406]\n",
      " [-33.54651 ]\n",
      " [-33.595367]\n",
      " [-33.644043]\n",
      " [-33.692505]\n",
      " [-33.740784]\n",
      " [-33.78882 ]\n",
      " [-33.83667 ]\n",
      " [-33.88434 ]\n",
      " [-33.931793]\n",
      " [-33.979095]\n",
      " [-34.026154]\n",
      " [-34.07306 ]\n",
      " [-34.11972 ]\n",
      " [-34.16626 ]\n",
      " [-34.212555]\n",
      " [-34.258698]\n",
      " [-34.304626]\n",
      " [-34.350372]\n",
      " [-34.395996]\n",
      " [-34.441406]\n",
      " [-34.486664]\n",
      " [-34.531708]\n",
      " [-34.5766  ]\n",
      " [-34.621307]\n",
      " [-34.665863]\n",
      " [-34.710205]\n",
      " [-34.754364]\n",
      " [-34.79843 ]\n",
      " [-34.842255]\n",
      " [-34.885986]\n",
      " [-34.929504]\n",
      " [-34.97287 ]\n",
      " [-35.016052]\n",
      " [-35.059113]\n",
      " [-35.10199 ]\n",
      " [-35.144714]\n",
      " [-35.187317]\n",
      " [-35.229736]\n",
      " [-35.272034]\n",
      " [-35.314148]\n",
      " [-35.35611 ]\n",
      " [-35.39795 ]\n",
      " [-35.439636]\n",
      " [-35.4812  ]\n",
      " [-35.522552]\n",
      " [-35.563843]\n",
      " [-35.60495 ]\n",
      " [-35.645935]\n",
      " [-35.686768]\n",
      " [-35.727478]\n",
      " [-35.768036]\n",
      " [-35.80847 ]\n",
      " [-35.848785]\n",
      " [-35.888916]\n",
      " [-35.928986]\n",
      " [-35.96884 ]\n",
      " [-36.008667]\n",
      " [-36.04831 ]\n",
      " [-36.08783 ]\n",
      " [-36.127228]\n",
      " [-36.166473]\n",
      " [-36.205658]\n",
      " [-36.24469 ]\n",
      " [-36.28357 ]\n",
      " [-36.322357]\n",
      " [-36.361053]\n",
      " [-36.399628]\n",
      " [-36.43802 ]\n",
      " [-36.47635 ]\n",
      " [-36.514557]\n",
      " [-36.552643]\n",
      " [-36.590576]\n",
      " [-36.62845 ]\n",
      " [-36.6662  ]\n",
      " [-36.703857]\n",
      " [-36.741333]\n",
      " [-36.778778]\n",
      " [-36.8161  ]\n",
      " [-36.853302]\n",
      " [-36.89038 ]\n",
      " [-36.9274  ]\n",
      " [-36.964264]\n",
      " [-37.00107 ]\n",
      " [-37.03775 ]\n",
      " [-37.07434 ]\n",
      " [-37.11084 ]\n",
      " [-37.147186]\n",
      " [-37.183502]\n",
      " [-37.219696]\n",
      " [-37.255768]\n",
      " [-37.291748]\n",
      " [-37.327667]\n",
      " [-37.363495]\n",
      " [-37.39917 ]\n",
      " [-37.434814]\n",
      " [-37.54059 ]\n",
      " [-37.575836]\n",
      " [-37.610962]\n",
      " [-37.646027]\n",
      " [-37.681   ]\n",
      " [-37.71591 ]\n",
      " [-37.750732]\n",
      " [-37.78543 ]\n",
      " [-37.820038]\n",
      " [-37.854614]\n",
      " [-37.88907 ]\n",
      " [-37.923462]\n",
      " [-37.957733]\n",
      " [-37.991974]\n",
      " [-38.026123]\n",
      " [-38.06021 ]\n",
      " [-38.094177]\n",
      " [-38.128082]\n",
      " [-38.161896]\n",
      " [-38.195618]\n",
      " [-38.229298]\n",
      " [-38.262848]\n",
      " [-38.296356]\n",
      " [-38.329773]\n",
      " [-38.36316 ]\n",
      " [-38.396423]\n",
      " [-38.429626]\n",
      " [-38.462738]\n",
      " [-38.495758]\n",
      " [-38.528778]\n",
      " [-38.561615]\n",
      " [-38.594482]\n",
      " [-38.627228]\n",
      " [-38.659943]\n",
      " [-38.692535]\n",
      " [-38.725067]\n",
      " [-38.757538]\n",
      " [-38.789948]\n",
      " [-38.822296]\n",
      " [-38.854523]\n",
      " [-38.88672 ]\n",
      " [-38.918854]\n",
      " [-38.950928]\n",
      " [-38.98294 ]\n",
      " [-39.014862]\n",
      " [-39.046753]\n",
      " [-39.07852 ]\n",
      " [-39.11026 ]\n",
      " [-39.141937]\n",
      " [-39.173523]\n",
      " [-39.20508 ]\n",
      " [-39.236572]\n",
      " [-39.267975]\n",
      " [-39.299347]\n",
      " [-39.330658]\n",
      " [-39.361877]\n",
      " [-39.393066]\n",
      " [-39.424164]]\n"
     ]
    }
   ],
   "source": [
    "polygon_points = [(100.0, 30.0), (120.0, 30.0), (120.0, 50.0), (100.0, 50.0)]\n",
    "print(polygon_points[0][0])\n",
    "\n",
    "#Test the polygon function with a polygon and one of the data files\n",
    "filtered_points = polygon(polygon_points, file_list[0])\n",
    "\n",
    "print(filtered_points.GEO_LON.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
